{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"cJhYo0ZUjH25"},"outputs":[],"source":["%%capture output\n","!pip install -q -U bitsandbytes\n","!pip install -q -U git+https://github.com/huggingface/transformers.git\n","!pip install -q -U git+https://github.com/huggingface/peft.git\n","!pip install -q -U git+https://github.com/huggingface/accelerate.git\n","!pip install -q -U datasets scipy ipywidgets matplotlib\n","!pip install datasets"]},{"cell_type":"code","source":["# hide output\n","%%capture output\n","\n","! pip install pdfplumber\n","! pip install chromadb\n","! pip install pymilvus\n","! pip install sentence-transformers\n","! pip install langchain\n","! pip install pypdf\n","! pip install faiss-gpu\n","! pip install happytransformer"],"metadata":{"id":"EW9ugSksmD9q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","from google.colab import drive\n","# Access drive\n","drive.mount('/content/drive')\n","path = '/content/drive/MyDrive/Capstone/'\n","\n","\n","# companies\n","companies = os.listdir(os.path.join(path, 'Company Reports'))\n","for i, comp in enumerate(companies):\n","    print(i, \": \", comp)\n","\n","\n","# get reports\n","def get_reports(comp, year:int, rep_type:int = 1):\n","    \"\"\"\n","    comp:       string or index\n","    year:       specific year or # recent year, 0 for all\n","    rep_type:   report type, 1 for annual report, 2 for sustainability report, 0 for both\n","    ret:        list of report pathes\n","    \"\"\"\n","    if type(comp) == str:\n","        if comp not in companies:\n","            print(\"Error: \", comp, \" does not exist\")\n","            return\n","    elif type(comp) == int:\n","        if comp not in range(len(companies)):\n","            print(\"Error: invalid index\")\n","            return\n","        comp = companies[comp]\n","    else:\n","        print(\"Error: invalid company\")\n","        return\n","\n","    file_path = os.path.join(path, 'Company Reports', comp)\n","    files = os.listdir(file_path)\n","    files.sort(reverse=True)\n","\n","    years = range(2013,2023)\n","    if year in range(11):\n","        if year:\n","            years = years[-year:]\n","    else:\n","        years = [year]\n","\n","    if rep_type == 0:\n","        reps = [\"\", \"_sus\"]\n","    elif rep_type == 1:\n","        reps = [\"\"]\n","    elif rep_type == 2:\n","        reps = [\"_sus\"]\n","    else:\n","        print(\"Error: invalid report type\")\n","        return\n","\n","    ret = []\n","    for year in years:\n","        for rep in reps:\n","            file = comp + '_' + str(year) + rep + '.pdf'\n","            if file in files:\n","                ret.append(file)\n","    return [os.path.join(file_path, file) for file in ret]"],"metadata":{"id":"TjgeBow5lZz9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["file = get_reports(2, 2022, 1)\n","\n","file = file[0]\n","file"],"metadata":{"id":"1L2Rl9MXly60"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from langchain.document_loaders import PyPDFium2Loader\n","\n","loader = PyPDFium2Loader(file)\n","all_splits = loader.load()"],"metadata":{"id":"f3whhq-ul3-B"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from langchain.embeddings import HuggingFaceEmbeddings\n","from langchain.vectorstores import FAISS\n","\n","embeddings = HuggingFaceEmbeddings()\n","\n","vs_faiss = FAISS.from_documents(all_splits[:20], embeddings)"],"metadata":{"id":"vMppXGMYmUwQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["question = \"\"\"Dear Shareholders\"\"\"\n","\n","letter = vs_faiss.similarity_search(question, k=1)\n","start = letter[0].metadata['page']\n","input = all_splits[start].page_content + all_splits[start+1].page_content + all_splits[start+2].page_content"],"metadata":{"id":"PVS2OIwOmVjd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train = \"\"\"{\"input\": \"<Summarize> \"\"\"+input+\"\"\"\",\"output\":\"In the past three years, BP has embarked on a transformative journey from an international oil company to an integrated energy company. Despite global challenges, including a pandemic, war, and economic crises, BP's focus on safe and reliable operations remains paramount. While some improvements have been made, there were tragic incidents, emphasizing the need to maintain safety processes and a culture of care for employees.BP has demonstrated financial strength and progress in its transformation. In 2022, it achieved its highest upstream plant reliability on record, low production costs, and generated $40.9 billion in operating cash flow. The company increased its dividend by 21% and executed $11.25 billion in share buybacks. This reflects a commitment to a clear and disciplined financial frame.Regarding transformation, BP's capital investment in transition growth engines, such as renewable natural gas, offshore wind, and electric vehicle charging, has significantly increased. Emissions reduction efforts and project startups further demonstrate BP's dedication to sustainability.BP acknowledges the global energy trilemma: lower carbon, secure, and affordable energy. The company's integrated energy strategy is designed to address this challenge by contributing to the energy transition while maintaining energy supply.To support its strategy, BP plans to invest more in transition growth engines and oil and gas projects, aiming to have around two million barrels a day in production by 2030. These changes align with the company's net-zero goals across operations, production, and sales.BP's plan for growth and value creation is underpinned by execution and operational excellence. The company remains grateful for the support of its shareholders and the dedication of its employees.In summary, BP's transformation journey has led to increased financial strength, sustainability efforts, and a strategic plan for growth and value creation, all while addressing the global energy trilemma.\"}\"\"\""],"metadata":{"id":"tb1YAalynFA8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train = train.replace(\"\\n\", \"\").replace(\"\\r\",\"\")\n","train"],"metadata":{"id":"LoBI_7JTpyF8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import json\n","json_object = json.loads(train)\n","\n","with open(\"/content/drive/MyDrive/Capstone/train.json\", \"w\") as outfile:\n","    json.dump(json_object, outfile)"],"metadata":{"id":"jgvrDunDnqD8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from datasets import load_dataset\n","import os\n","from google.colab import drive\n","\n","\n","\n","train_dataset = load_dataset('json', data_files=\"/content/drive/MyDrive/Capstone/train.json\")\n","#eval_dataset = load_dataset('json', data_files='notes_validation.jsonl', split='train')"],"metadata":{"id":"_lWyZWmtjQpF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def formatting_func(example):\n","    text = f\"### Question: {example['input']}\\n ### Answer: {example['output']}\"\n","    return text"],"metadata":{"id":"goJZqYdtj6hy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# load base model\n","import torch\n","from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n","\n","base_model_id = \"mistralai/Mistral-7B-v0.1\"\n","bnb_config = BitsAndBytesConfig(\n","    load_in_4bit=True,\n","    bnb_4bit_use_double_quant=True,\n","    bnb_4bit_quant_type=\"nf4\",\n","    bnb_4bit_compute_dtype=torch.bfloat16\n",")\n","\n","model = AutoModelForCausalLM.from_pretrained(base_model_id, quantization_config=bnb_config)"],"metadata":{"id":"4JkR_6rJj-QK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Tokenization\n","tokenizer = AutoTokenizer.from_pretrained(\n","    base_model_id,\n","    padding_side=\"left\",\n","    add_eos_token=True,\n","    add_bos_token=True,\n",")\n","tokenizer.pad_token = tokenizer.eos_token\n","\n","def generate_and_tokenize_prompt(prompt):\n","    return tokenizer(formatting_func(prompt))"],"metadata":{"id":"HHORu7KCsh_a"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokenized_train_dataset = train_dataset.map(generate_and_tokenize_prompt)\n"],"metadata":{"id":"InlWFAPJzck0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# set up Lora\n","\n","from peft import prepare_model_for_kbit_training\n","\n","model.gradient_checkpointing_enable()\n","model = prepare_model_for_kbit_training(model)"],"metadata":{"id":"wqXf4zK_063F"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def print_trainable_parameters(model):\n","    \"\"\"\n","    Prints the number of trainable parameters in the model.\n","    \"\"\"\n","    trainable_params = 0\n","    all_param = 0\n","    for _, param in model.named_parameters():\n","        all_param += param.numel()\n","        if param.requires_grad:\n","            trainable_params += param.numel()\n","    print(\n","        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n","    )"],"metadata":{"id":"_y37RerC1AMu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from peft import LoraConfig, get_peft_model\n","\n","config = LoraConfig(\n","    r=32,\n","    lora_alpha=64,\n","    target_modules=[\n","        \"q_proj\",\n","        \"k_proj\",\n","        \"v_proj\",\n","        \"o_proj\",\n","        \"gate_proj\",\n","        \"up_proj\",\n","        \"down_proj\",\n","        \"lm_head\",\n","    ],\n","    bias=\"none\",\n","    lora_dropout=0.05,  # Conventional\n","    task_type=\"CAUSAL_LM\",\n",")\n","\n","model = get_peft_model(model, config)\n","print_trainable_parameters(model)"],"metadata":{"id":"fcXLTOMj1Hb-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Set up Accelarator\n","from accelerate import FullyShardedDataParallelPlugin, Accelerator\n","from torch.distributed.fsdp.fully_sharded_data_parallel import FullOptimStateDictConfig, FullStateDictConfig\n","\n","fsdp_plugin = FullyShardedDataParallelPlugin(\n","    state_dict_config=FullStateDictConfig(offload_to_cpu=True, rank0_only=False),\n","    optim_state_dict_config=FullOptimStateDictConfig(offload_to_cpu=True, rank0_only=False),\n",")\n","\n","accelerator = Accelerator(fsdp_plugin=fsdp_plugin)"],"metadata":{"id":"woItc6CR2LM0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","model = accelerator.prepare_model(model)"],"metadata":{"id":"FiG-PojO2Y0L"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install -q wandb -U\n","\n","import wandb, os\n","wandb.login()\n","\n","wandb_project = \"journal-finetune\"\n","if len(wandb_project) > 0:\n","    os.environ[\"WANDB_PROJECT\"] = wandb_project"],"metadata":{"id":"IAvtEO2g2aXU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Run training\n","if torch.cuda.device_count() > 1: # If more than 1 GPU\n","    model.is_parallelizable = True\n","    model.model_parallel = True"],"metadata":{"id":"rjIJhrko2cFf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import transformers\n","from datetime import datetime\n","\n","project = \"journal-finetune\"\n","base_model_name = \"mistral\"\n","run_name = base_model_name + \"-\" + project\n","output_dir = \"./\" + run_name\n","\n","trainer = transformers.Trainer(\n","    model=model,\n","    train_dataset=tokenized_train_dataset,\n","    eval_dataset=tokenized_val_dataset,\n","    args=transformers.TrainingArguments(\n","        output_dir=output_dir,\n","        warmup_steps=1,\n","        per_device_train_batch_size=2,\n","        gradient_accumulation_steps=1,\n","        max_steps=500,\n","        learning_rate=2.5e-5, # Want a small lr for finetuning\n","        bf16=True,\n","        optim=\"paged_adamw_8bit\",\n","        logging_steps=25,              # When to start reporting loss\n","        logging_dir=\"./logs\",        # Directory for storing logs\n","        save_strategy=\"steps\",       # Save the model checkpoint every logging step\n","        save_steps=25,                # Save checkpoints every 50 steps\n","        evaluation_strategy=\"steps\", # Evaluate the model every logging step\n","        eval_steps=25,               # Evaluate and save checkpoints every 50 steps\n","        do_eval=True,                # Perform evaluation at the end of training\n","        report_to=\"wandb\",           # Comment this out if you don't want to use weights & baises\n","        run_name=f\"{run_name}-{datetime.now().strftime('%Y-%m-%d-%H-%M')}\"          # Name of the W&B run (optional)\n","    ),\n","    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False),\n",")\n","\n","model.config.use_cache = False  # silence the warnings. Please re-enable for inference!\n","trainer.train()"],"metadata":{"id":"RWAcN5m12ebv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n","\n","base_model_id = \"mistralai/Mistral-7B-v0.1\"\n","bnb_config = BitsAndBytesConfig(\n","    load_in_4bit=True,\n","    bnb_4bit_use_double_quant=True,\n","    bnb_4bit_quant_type=\"nf4\",\n","    bnb_4bit_compute_dtype=torch.bfloat16\n",")\n","\n","base_model = AutoModelForCausalLM.from_pretrained(\n","    base_model_id,  # Mistral, same as before\n","    quantization_config=bnb_config,  # Same quantization config as before\n","    device_map=\"auto\",\n","    trust_remote_code=True,\n","    use_auth_token=True\n",")\n","\n","tokenizer = AutoTokenizer.from_pretrained(base_model_id, add_bos_token=True, trust_remote_code=True)"],"metadata":{"id":"QmT8WDya2lDB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from peft import PeftModel\n","\n","ft_model = PeftModel.from_pretrained(base_model, \"mistral-journal-finetune/checkpoint-300\")\n"],"metadata":{"id":"Lae5V1Km2qHa"},"execution_count":null,"outputs":[]}]}